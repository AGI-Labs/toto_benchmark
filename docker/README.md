# Docker Instructions

## Requirements
1. Install [nvidia-docker v2](https://github.com/NVIDIA/nvidia-docker) following instructions here: [https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker).
Note: only supports Linux; no Windows or MacOS.
2. Cuda version >= 11.4 should be installed on the host.

## Build Docker Image

```
docker build . -t toto_benchmark:deploy
```

## Run Docker Container interactively (with the dataset mounted)
- DATASETS_PATH: the path on the host machine which contains the toto benchmark dataset
```
docker run -v $DATASETS_PATH:$DATASETS_PATH -it --runtime=nvidia --shm-size 8G --gpus all toto_benchmark:deploy
```
example usage:
```
docker run -v /totodata:/totodata -it --runtime=nvidia --shm-size 8G --gpus all toto_benchmark:deploy
```

## Train the agent (from docker container interactive shell)
```
cd toto_benchmark/scripts
python train.py --config-name train_bc.yaml data.pickle_fn=/cloud-dataset-pouring-v0/parsed_with_embeddings_moco_conv5_robocloud.pkl
```

## Test the agent locally in a dummy environment (from docker container interactive shell)
- AGENT_PATH: should contain a hydra.yaml file either generated by the training script or manually added. Please refer to conf/train_bcimage.yaml for reference.
```
python test_stub_env.py -f AGENT_PATH
```
example usage
```
cd toto_benchmark
python test_stub_env.py -f ./outputs/dummy_agent
```